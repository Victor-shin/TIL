# 9장 스파크 스트리밍

9장에서 다루는 내용

* 스트리밍에 대한 간단한 소개
* 스파크 스트리밍
* 불연속 스트림(Discretized Stream)
* 상태 저장/무상태 트랜스포메이션
* 체크포인팅
* 스트리밍 플랫폼과의 상호운용성(아파치 카프카)
* 구조화 스트리밍

## 스트리밍에 대한 간략한 소개
* 모든 것이 빠르게 움직이고 있다. 변화와 실패에 반응해야 한다.
* 데이터 흐름, 처리, 사용은 모두 최대한 실시간에 가깝게 하는 것이 필수적이다.

실시간 스트리밍 데이터 처리는 다음과 같은 세 가지의 필수 처리 방식으로 분류할 수 있다.
* 최소 한 번 처리
* 최대 한 번 처리
* 정확히 한 번 처리


### 최소 한 번 처리 방식
1. 결과를 저장한다.
1. 오프셋을 저장한다.

### 최대 한 번 처리 방식
1. 오프셋을 저장한다.
1. 결과를 저장한다.

### 정확히 한 번 처리
1. 결과를 저장한다.
1. 오프셋을 저장한다.

중복을 제거하는 기술

1. 멱등성(idempotent) 업데이트
1. 트랜잭션(transaction) 업데이트


## 스파크 스트리밍
* RDD = SparkContext
* 스파크 스트리밍 = StreamingContext
* StreamingContext는 SparkContext에 의존한다.

### StreamingContext

#### StreamingContext 생성

새로운 StreamingContext 생성 방법 3가지 (P.462)

1. 기존 SparkContext를 사용해 StreamingContext를 생성한다.
1. SparkContext를 생성하는데 필요한 설정을 제공해 StreamingContext를 생성한다.
1. 체크 포인팅 데이터에서 StreamingContext를 재생성하거나 새로운 StreamingContext를 생성하기 위해 사용되는 getOrCreate()를 사용한다.

#### StreamingContext 시작

#### StreamingContext 중지 


### 입력 스트림

#### receiverStream

#### socketTextStream

#### rawSocketStream

#### fileStream

#### textFileStream

#### binaryRecordsStream

#### queueStream

#### textFileStream

#### twitterStream


## 불연속 스트림
* 스파크 스트리밍은 불연속 스트림(Discreteized Stream) 또는 DStream이라는 추상화를 기반으로 생성된다.
* DStream은 비순환 방향 그래프(Directed Acyclic Graph)와 같은 유사한 개념을 사용해 일반 RDD와 비슷한 방식으로 처리할 수 있다.

스트리밍 애플리케이션을 작성하는 과정은 다음과 같다.

1. SparkContext에서 StreamingContext를 생성
1. StreamingContext에서 DStream를 생성
1. 각 RDD에 적용될 수 있는 트랜스포메이션과 액션을 제공
1. 마지막으로 StreamingContext에서 start()를 호출해서 스트리밍 애플리케이션을 시작한다. 스트리밍 애플리케이션은 실시간 이벤트를 소비하고 처리하는 전체 프로세스를 시작한다.


> TIP

    스파크 스트리밍 애플리케이션이 시작되면 더 이상 연산을 추가할 수 없다. 중지된  컨텍스트를 재시작할 수 없으며, 필요성이 있다면 새로운 스트리밍 컨텍스트를 생성해야 한다.

### 트랜스포메이션
* 스파크 코어 RDD에 적용되는 트랜스포메이션과 유사하다.

### 윈도우 연산
<!> 이해가 부족함! 상태 저장 트랜스포메이션도 봐야 한다.


## 상태 저장/상태 비저장 트랜스포메이션
DStream에 대한 트랜스포메이션은 상태 비저장(Stateless) 트랜스포메이션과 상태 저장(Stateful) 트랜스포메이션의 두 가지 타입으로 그룹핑할 수 있다.

### 상태 비저장 트랜스포메이션

### 상태 저장 트랜스포메이션
<!> 윈도우 연산과 함께 한 번 더 봐야 한다.


## 체크 포인팅
* 실시간 스트리밍 애플리케이션은 어떠한 실패가 발생하더라도 오랫동안 실행돼야 하고 복원력이 있어야 한다.
* 스파크 스트리밍은 실패로부터 복구할 수 있는 충분한 정보를 유지 관리하는 체크 포인팅(checkpointing) 기능을 갖고 있다.

체크 포인팅이 필요한 두 가지 타입의 데이터

* 메타데이터 체크 포인팅
* 데이터 체크 포인팅

> TIP

    체크 포인팅 데이터가 저장될 디렉토리는 HDFS와 같은 내결함성(fault-tolerant) 파일 시스템이어야 한다.

### 메타데이터 체크 포인팅
메타데이터 체크 포인팅은 스트리밍 연산을 정의하는 정보를 저장한다.
해당 정보는 DAG로 표시돼 HDFS에 저장된다.

메타데이터에는 다음을 포함한다.

* 설정
* DStream 연산
* 불완전한 배치

### 데이터 체크포인팅

* 상태 저장 트랜스포메이션 사용 
* 애플리케이션을 실행하는 드라이버의 실패를 복구하기

<!> 이해가 부족함!

### 드라이버 실패 복구


## 스트리밍 플랫폼과의 상호 운용성(아파치 카프카)
스파크 스트리밍은 아파치 카프카와 매우 잘 통합돼 있다.

스파크 스트리밍과 카프카를 통합하는 3가지 주요 접근 방식

* 수신기 기반 접근 방식
* 다이렉트 스트림 접근 방식
* 구조화 스트리밍 

### 수신기 기반 접근 방식

### 다이렉트 스트림 접근 방식 

### 구조화 스트리밍
스파크 2.2 GA 릴리스 버전부터 사용할 수 있다.


## 구조화 스트리밍
스파크 SQL 엔진 위에 구축된 확장 가능하고 내결함성 스트림 처리 엔진이다.

### 이벤트 시간과 지연 데이터 처리

### 내 결함성 의미 체계


## 요약



