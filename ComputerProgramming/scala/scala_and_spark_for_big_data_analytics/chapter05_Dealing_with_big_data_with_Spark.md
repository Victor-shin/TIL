# 5장 스파크로 빅데이터 다루기
5장에서 다루는 내용

* 데이터 분석 소개
* 빅데이터 소개
* 하둡을 사용한 분산 컴퓨팅
* 아파치 스파크

## 데이터 분석 소개
* EDA(Exploratory Data Analysis) 
데이터에서 패턴을 찾을 때 의미 있는 데이터를 분석하고 데이터의 여러 엘리먼트 간의 관계를 찾기 위해 사용되는 바업ㅂ론, 툴, 기술을 포함한다.
* CDA(Confirmatory Data Analysis)
가설, 통계 기법 또는 간단히 살펴본 데이터를 기반으로 특정 질문에 대한 통찰력이나 결과를 제공하는 데 사용되는 방법론, 툴, 기법을 포함한다.
### 데이터 분석 프로세스 내부
* 분석을 계획하기 전에 준비되어야 하는 작업 
  * 데이터 수집
  * 통합
  * 준비
  * 데이터 품질 확인
  * 분석 방법의 개발/테스팅

## 빅데이터 소개
### 빅데이터의 4V
* 데이터의 다양성(variety)
* 데이터 속도(velocity)
* 데이터의 볼륨(volume)
* 데이터의 진실성(veracity)

## 하둡을 이용한 분석 컴퓨팅
### 하둡 분산 파일 시스템(HDFS)
#### HDFS 고가용성
#### HDFS 페더레이션
#### HDFS 스냅샷
네임 노드 메타데이터를 사용해 디렉토리를 복사할 수 있다.
#### HDFS 읽기
#### HDFS 저장

### 맵리듀스 프레임워크

## 아파치 스파크
데이터 작업자가 스트리밍 머신 러닝을 실행하거나 데이터셋에 대해 빠른 대화식 접근이 필요한 SQL 작업 부하를 효율적으로 실행할 수 있게 고급스럽고 풍부한 API를 갖춘 빠른 인메모리 데이터 처리 엔진이다.

스파크가 맵 리듀스 패러다임에 비해 가지는 중요한 장점
* 가능한 한 많이 인메모리에서 처리한다.
* 배치, 실시간 작업에 사용할 수 있는 범용 엔진이다.
* 얀과 메소스와 호환 가능하다.
* HBase, 카산드라, 몽고DB, HDFS, 아마존 S3, 기타 파일 시스템과 데이터 소스와 잘 통합된다.
### 스파크 코어
### 스파크 SQL
### 스파크 스트리밍
### 스파크 GraphX
### 스파크 ML
### PySpark 
### SparkR

## 요약
.
