# 19장 PySpark와 SparkR

19장에서 다루는 내용 

* PySpark 소개
* PySpark로 설치와 시작
* 데이터 프레임 API와 상호작용 
* PySpark에서 UDF 작성
* PySpark를 이용한 데이터 분석
* SparkR 소개
* 왜 SparkR인가?
* SparkR로 설치와 시작
* 데이터 처리와 조작
* SparkR을 사용한 RDD와 데이터 프레임 작업
* SparkR을 사용한 데이터 시각화


## PySpark 소개
파이썬이 통계, 머신 러닝, 최적화에 초점을 맞춘 다양한 수치 라이브러리를 보유하고 있기 때문에 많은 데이터 과학자는 파이썬을 사용한다.

파이썬 셸을 통해 실험과 개발을 충분히 진행할 수 있다.
그러나 상용 환경에서는 독립형 애플리케이션을 사용해야 한다.

## SparkR 소개
R은 통계 컴퓨팅, 데이터 처리, 머신 러닝 작업을 지원하는 흥미롭고 많은 기능을 갖춘 가장 널리 사용되는 통계 프로그래밍 언어 중 하나다.
R은 런타임이 단일 스레드이기 때문에 느리다.

### SparkR의 사용 이유
스파크 MLlib를 사용해 분산된 머신 러닝을 지원하는 SparkR을 사용해 스파크 코드를 작성할 수 있다.

SparkR은 다음을 포함해 스파크와 긴밀하게 통합하는 많은 장점을 얻을 수 있다.

* 다양한 데이터 소스 API 지원
* 데이터 프레임 최적화
* 확장성

## 요약


